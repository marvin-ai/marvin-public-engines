{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquisitor and Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "marvin_cell": "acquisitor"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rafael/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from marvin_python_toolbox.common.data import MarvinData\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('portuguese')\n",
    "\n",
    "initial_dataset = pd.read_csv(\n",
    "    MarvinData.download_file(\"https://s3.amazonaws.com/automl-example/produtos.csv\"),\n",
    "    delimiter=\";\", encoding='utf-8')\n",
    "\n",
    "def remove_nonlatin(string):\n",
    "    new_chars = []\n",
    "    for char in string:\n",
    "        if char == '\\n':\n",
    "            new_chars.append(' ')\n",
    "            continue\n",
    "        try:\n",
    "            if unicodedata.name(char).startswith(('LATIN', 'SPACE')):\n",
    "                new_chars.append(char)\n",
    "        except:\n",
    "            continue\n",
    "    return ''.join(new_chars)\n",
    "\n",
    "def pre_processor(text):\n",
    "    stops = set(stopwords.words(\"portuguese\"))\n",
    "    text = remove_nonlatin(text)\n",
    "    words = text.lower().split()\n",
    "    words = ' '.join([w for w in words if not w in stops])\n",
    "    return words\n",
    "\n",
    "initial_dataset[\"text\"] = initial_dataset[\"nome\"] + \" \" + initial_dataset[\"descricao\"]\n",
    "initial_dataset.drop([\"descricao\", \"nome\"], axis=1, inplace=True)\n",
    "initial_dataset.dropna(inplace=True)\n",
    "initial_dataset['text'] = initial_dataset['text'].apply(pre_processor)\n",
    "\n",
    "marvin_initial_dataset = initial_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training preparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "marvin_cell": "tpreparator"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    marvin_initial_dataset[\"text\"], \n",
    "    marvin_initial_dataset[\"categoria\"], \n",
    "    test_size = 0.2, \n",
    "    random_state = 10\n",
    ")\n",
    "\n",
    "vect = CountVectorizer()\n",
    "vect.fit(marvin_initial_dataset[\"text\"])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(marvin_initial_dataset[\"categoria\"])\n",
    "\n",
    "marvin_dataset = {\n",
    "    \"X_train\": vect.transform(X_train),\n",
    "    \"X_test\": vect.transform(X_test),\n",
    "    \"y_train\": encoder.transform(y_train),\n",
    "    \"y_test\" : encoder.transform(y_test),\n",
    "    \"vect\": vect,\n",
    "    \"encoder\": encoder\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "marvin_cell": "trainer"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2018-05-08 17:01:11,505:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-05-08 17:01:11,505:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n"
     ]
    }
   ],
   "source": [
    "import autosklearn.classification as automl\n",
    "\n",
    "clf = automl.AutoSklearnClassifier(\n",
    "    include_preprocessors=[\"no_preprocessing\",],\n",
    "    exclude_preprocessors=None\n",
    ")\n",
    "clf.fit(marvin_dataset[\"X_train\"], marvin_dataset[\"y_train\"])\n",
    "\n",
    "marvin_model = {\n",
    "    \"clf\" : clf,\n",
    "    \"vect\": marvin_dataset[\"vect\"],\n",
    "    \"encoder\": marvin_dataset[\"encoder\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "marvin_cell": "evaluator"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.97      0.98       142\n",
      "          1       0.98      1.00      0.99       122\n",
      "          2       0.99      0.99      0.99       156\n",
      "          3       1.00      0.98      0.99       164\n",
      "\n",
      "avg / total       0.99      0.99      0.99       584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "y_prediction = marvin_model[\"clf\"].predict(marvin_dataset[\"X_test\"])\n",
    "\n",
    "report = classification_report(y_prediction, marvin_dataset[\"y_test\"])\n",
    "\n",
    "print(report)\n",
    "\n",
    "marvin_metrics = report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = [\"God of War\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "marvin_cell": "ppreparator"
   },
   "outputs": [],
   "source": [
    "input_message = marvin_model[\"vect\"].transform([input_message])\n",
    "input_message = input_message.toarray().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "marvin_cell": "predictor"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_message = np.array(input_message)\n",
    "pred = self.marvin_model[\"clf\"].predict(input_message)[0]\n",
    "final_prediction = self.marvin_model[\"encoder\"].classes_[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
